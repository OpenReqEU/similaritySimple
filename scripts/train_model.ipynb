{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import simplejson\n",
    "import string\n",
    "from gensim.models import FastText\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean( txt ):\n",
    "    #txt = str(txt)\n",
    "    return txt \n",
    "def get_embedding( text ,  model , N = 200 ):\n",
    "\n",
    "    text = text_clean( text )\n",
    "\n",
    "    embedding = np.zeros(  ( N ) )\n",
    "    words = text.split(\" \")\n",
    "    for word in words:\n",
    "    \n",
    "        #if word in model:\n",
    "        emb =  model.wv[word]\n",
    "        embedding += emb\n",
    "        #else:\n",
    "        #embedding += np.zeros( (N) )\n",
    "\n",
    "    embedding /= len( words )\n",
    "\n",
    "    return embedding\n",
    "def norm_vec(  a ):\n",
    "    # function to normalize vectors \n",
    "\n",
    "    a = a / np.sqrt( (a*a).sum(axis = 1 ) ).reshape( a.shape[0]  , 1 )\n",
    "\n",
    "    return  np.nan_to_num( a ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpurs():\n",
    "    \n",
    "    # extracts text data from the siemems files\n",
    "    files = os.listdir(\"../data/\")\n",
    "    ind = 0\n",
    "    mapping = {}\n",
    "    ids2text = {} \n",
    "    data = []\n",
    "    files_json = [ f for f in files if f.endswith(\".json\")]\n",
    "\n",
    "    corpus = \"\"\n",
    "    for f in files_json:\n",
    "        print(f)\n",
    "        fh = open( \"../data/\" + f )\n",
    "        #print( type(data))\n",
    "        #print( data[:1000] )\n",
    "        json_data = simplejson.load( fh )\n",
    "\n",
    "        for req in json_data:\n",
    "\n",
    "            if req[\"requirement_type\"] != \"DEF\":\n",
    "\n",
    "                if \"text\" in req:\n",
    "                    txt = req[\"text\"]\n",
    "                if txt is None:\n",
    "                    continue\n",
    "                txt = txt.lower()\n",
    "                txt = txt.strip() \n",
    "                txt = txt.replace(\"\\t\" , \" \")\n",
    "                txt = txt.encode(\"utf-8\" , \"ignore\")\n",
    "                #txt = str(txt)\n",
    "                txt = txt.translate( string.maketrans(\"\",\"\"), string.punctuation  )\n",
    "\n",
    "\n",
    "                txt = ' '.join(txt.split())\n",
    "                txt = txt.decode(\"utf-8\")\n",
    "                corpus += txt + \"\\n\"\n",
    "                continue\n",
    "            if \"text\" in req:\n",
    "                txt = req[\"text\"]\n",
    "                if txt is None:\n",
    "                    continue\n",
    "                txt = txt.lower()\n",
    "                txt = txt.strip() \n",
    "                txt = txt.replace(\"\\t\" , \" \")\n",
    "                txt = txt.encode(\"utf-8\" , \"ignore\")\n",
    "                txt = txt.translate( string.maketrans(\"\",\"\"), string.punctuation  )\n",
    "\n",
    "                \n",
    "\n",
    "                if txt != \"\":\n",
    "                    data.append( txt )\n",
    "                    txt = ' '.join( txt.split())\n",
    "                    txt = txt.decode(\"utf-8\")\n",
    "                    corpus +=  txt + \"\\n\"\n",
    "                    mapping[ ind] = req[\"id\"]\n",
    "                    ids2text[ req[\"id\"] ] = {}\n",
    "                    ids2text[ req[\"id\"] ][\"text\"] = txt\n",
    "                    ids2text[ req[\"id\"] ][\"project\"] = f\n",
    "                    ind += 1\n",
    "                    \n",
    "    return corpus , mapping , data , ids2text\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus , mapping , data , ids2text = create_corpurs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(corpus, sg=1, hs=1, size=100, workers=4, iter=5, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.zeros(  (  ind , 200 ))\n",
    "\n",
    "i = 0 \n",
    "for r in data:\n",
    "    r = r.decode(\"utf-8\")\n",
    "    #print(r)\n",
    "    vec = get_embedding( r , model  )\n",
    "\n",
    "    vectors[ i , : ] = vec\n",
    "    i += 1\n",
    "vectors = vectors.astype( np.float32 )\n",
    "\n",
    "vectors = norm_vec( vectors )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model, mappings , data and ids2text\n",
    "pickle.dump( file= open(\"../data/siemens_200.bin\" , \"w\") , obj=model , protocol=2 )  # dump model\n",
    "np.save(arr=vectors ,file=\"../data/embeddings.npy\") # vectors\n",
    "\n",
    "pickle.dump( file=open(\"../data/mappings.bin\" , \"w\") , obj=mapping )\n",
    "pickle.dump( file=open(\"../data/ids2info.bin\" , \"w\") , obj=ids2text )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
